{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0192ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import flwr as fl\n",
    "from flwr.client import ClientApp, NumPyClient\n",
    "from flwr.server import ServerApp, ServerConfig, ServerAppComponents\n",
    "from flwr.server.strategy import FedAvg\n",
    "from flwr.simulation import run_simulation\n",
    "from flwr.common import Context, ndarrays_to_parameters, parameters_to_ndarrays\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "addf589f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 5 * 5, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3c82f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights(model):\n",
    "    return [val.cpu().numpy() for val in model.state_dict().values()]\n",
    "\n",
    "def set_weights(model, weights):\n",
    "    state_dict = model.state_dict()\n",
    "    for k, v in zip(state_dict.keys(), weights):\n",
    "        state_dict[k] = torch.tensor(v)\n",
    "    model.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "def train(model, loader, epochs=1):\n",
    "    model.train()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for _ in range(epochs):\n",
    "        for x, y in loader:\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(x)\n",
    "            loss = criterion(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "def test(model, loader):\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    loss_total, correct, total = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            out = model(x)\n",
    "            loss = criterion(out, y)\n",
    "            loss_total += loss.item()\n",
    "            _, pred = torch.max(out, 1)\n",
    "            correct += (pred == y).sum().item()\n",
    "            total += y.size(0)\n",
    "            y_true.extend(y.numpy())\n",
    "            y_pred.extend(pred.numpy())\n",
    "    return loss_total / len(loader), correct / total, y_true, y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f1aa2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "full_train = MNIST(root=\".\", train=True, download=True, transform=transform)\n",
    "testset = MNIST(root=\".\", train=False, download=True, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=32)\n",
    "\n",
    "def partition_dataset(dataset, num_partitions):\n",
    "    size = len(dataset) // num_partitions\n",
    "    return [Subset(dataset, list(range(i * size, (i + 1) * size))) for i in range(num_partitions)]\n",
    "\n",
    "num_clients = 5\n",
    "partitions = partition_dataset(full_train, num_clients)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f18b728",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowerClient(NumPyClient):\n",
    "    def __init__(self, cid, trainloader):\n",
    "        self.model = Net()\n",
    "        self.trainloader = trainloader\n",
    "        self.cid = cid\n",
    "\n",
    "    def get_parameters(self, config): return get_weights(self.model)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        set_weights(self.model, parameters)\n",
    "        train(self.model, self.trainloader)\n",
    "        return get_weights(self.model), len(self.trainloader.dataset), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        set_weights(self.model, parameters)\n",
    "        loss, acc, _, _ = test(self.model, testloader)\n",
    "        return loss, len(testloader.dataset), {\"accuracy\": acc}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "789b3e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_fn(context: Context):\n",
    "    cid = int(context.node_config.get(\"partition_id\", 0))\n",
    "    trainloader = DataLoader(partitions[cid], batch_size=32, shuffle=True)\n",
    "    return FlowerClient(cid, trainloader).to_client()\n",
    "\n",
    "client_app = ClientApp(client_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4ed22d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def server_fn(context: Context) -> ServerAppComponents:\n",
    "    model = Net()\n",
    "    initial_parameters = ndarrays_to_parameters(get_weights(model))\n",
    "\n",
    "    def evaluate_fn(server_round, parameters, _):\n",
    "        global final_weights\n",
    "        final_weights = parameters_to_ndarrays(parameters)\n",
    "        set_weights(model, final_weights)\n",
    "        loss, acc, _, _ = test(model, testloader)\n",
    "        print(f\"[Server] Round {server_round} - acc: {acc:.4f}\")\n",
    "        return loss, {\"accuracy\": acc}\n",
    "    \n",
    "    def aggregate_fn(results):\n",
    "        total = sum([num for _, num, _ in results])\n",
    "        weighted = sum([r[2]['accuracy'] * r[1] for r in results])\n",
    "        return {\"accuracy\": weighted / total}\n",
    "\n",
    "\n",
    "    return ServerAppComponents(\n",
    "        config=ServerConfig(num_rounds=3),\n",
    "        strategy=FedAvg(\n",
    "        initial_parameters=initial_parameters,\n",
    "        evaluate_fn=evaluate_fn,\n",
    "        #fit_metrics_aggregation_fn=aggregate_fn\n",
    "    ),\n",
    "    )\n",
    "\n",
    "server = ServerApp(server_fn=server_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "988668b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=3, no round_timeout\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n",
      "\u001b[92mINFO \u001b[0m:      Evaluating initial global parameters\n",
      "\u001b[91mERROR \u001b[0m:     ServerApp thread raised an exception: 'list' object has no attribute 'tensors'\n",
      "\u001b[91mERROR \u001b[0m:     Traceback (most recent call last):\n",
      "  File \"c:\\Users\\delma\\OneDrive\\Bureau\\4eme_EI\\Artificial_Inteligence\\Intership_Steve_DELMAS_2025\\venv\\Lib\\site-packages\\flwr\\simulation\\run_simulation.py\", line 292, in server_th_with_start_checks\n",
      "    run_server_app(\n",
      "  File \"c:\\Users\\delma\\OneDrive\\Bureau\\4eme_EI\\Artificial_Inteligence\\Intership_Steve_DELMAS_2025\\venv\\Lib\\site-packages\\flwr\\server\\run_serverapp.py\", line 84, in run\n",
      "    server_app(driver=driver, context=context)\n",
      "  File \"c:\\Users\\delma\\OneDrive\\Bureau\\4eme_EI\\Artificial_Inteligence\\Intership_Steve_DELMAS_2025\\venv\\Lib\\site-packages\\flwr\\server\\server_app.py\", line 120, in __call__\n",
      "    start_driver(\n",
      "  File \"c:\\Users\\delma\\OneDrive\\Bureau\\4eme_EI\\Artificial_Inteligence\\Intership_Steve_DELMAS_2025\\venv\\Lib\\site-packages\\flwr\\server\\compat\\app.py\", line 90, in start_driver\n",
      "    hist = run_fl(\n",
      "           ^^^^^^^\n",
      "  File \"c:\\Users\\delma\\OneDrive\\Bureau\\4eme_EI\\Artificial_Inteligence\\Intership_Steve_DELMAS_2025\\venv\\Lib\\site-packages\\flwr\\server\\server.py\", line 490, in run_fl\n",
      "    hist, elapsed_time = server.fit(\n",
      "                         ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\delma\\OneDrive\\Bureau\\4eme_EI\\Artificial_Inteligence\\Intership_Steve_DELMAS_2025\\venv\\Lib\\site-packages\\flwr\\server\\server.py\", line 95, in fit\n",
      "    res = self.strategy.evaluate(0, parameters=self.parameters)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\delma\\OneDrive\\Bureau\\4eme_EI\\Artificial_Inteligence\\Intership_Steve_DELMAS_2025\\venv\\Lib\\site-packages\\flwr\\server\\strategy\\fedavg.py\", line 167, in evaluate\n",
      "    eval_res = self.evaluate_fn(server_round, parameters_ndarrays, {})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\delma\\AppData\\Local\\Temp\\ipykernel_1300\\3995451472.py\", line 7, in evaluate_fn\n",
      "    final_weights = parameters_to_ndarrays(parameters)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\delma\\OneDrive\\Bureau\\4eme_EI\\Artificial_Inteligence\\Intership_Steve_DELMAS_2025\\venv\\Lib\\site-packages\\flwr\\common\\parameter.py\", line 34, in parameters_to_ndarrays\n",
      "    return [bytes_to_ndarray(tensor) for tensor in parameters.tensors]\n",
      "                                                   ^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'list' object has no attribute 'tensors'\n",
      "\n",
      "Exception in thread Thread-30 (server_th_with_start_checks):\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\delma\\OneDrive\\Bureau\\4eme_EI\\Artificial_Inteligence\\Intership_Steve_DELMAS_2025\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\delma\\OneDrive\\Bureau\\4eme_EI\\Artificial_Inteligence\\Intership_Steve_DELMAS_2025\\venv\\Lib\\site-packages\\flwr\\simulation\\run_simulation.py\", line 292, in server_th_with_start_checks\n",
      "    run_server_app(\n",
      "  File \"c:\\Users\\delma\\OneDrive\\Bureau\\4eme_EI\\Artificial_Inteligence\\Intership_Steve_DELMAS_2025\\venv\\Lib\\site-packages\\flwr\\server\\run_serverapp.py\", line 84, in run\n",
      "    server_app(driver=driver, context=context)\n",
      "  File \"c:\\Users\\delma\\OneDrive\\Bureau\\4eme_EI\\Artificial_Inteligence\\Intership_Steve_DELMAS_2025\\venv\\Lib\\site-packages\\flwr\\server\\server_app.py\", line 120, in __call__\n",
      "    start_driver(\n",
      "  File \"c:\\Users\\delma\\OneDrive\\Bureau\\4eme_EI\\Artificial_Inteligence\\Intership_Steve_DELMAS_2025\\venv\\Lib\\site-packages\\flwr\\server\\compat\\app.py\", line 90, in start_driver\n",
      "    hist = run_fl(\n",
      "           ^^^^^^^\n",
      "  File \"c:\\Users\\delma\\OneDrive\\Bureau\\4eme_EI\\Artificial_Inteligence\\Intership_Steve_DELMAS_2025\\venv\\Lib\\site-packages\\flwr\\server\\server.py\", line 490, in run_fl\n",
      "    hist, elapsed_time = server.fit(\n",
      "                         ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\delma\\OneDrive\\Bureau\\4eme_EI\\Artificial_Inteligence\\Intership_Steve_DELMAS_2025\\venv\\Lib\\site-packages\\flwr\\server\\server.py\", line 95, in fit\n",
      "    res = self.strategy.evaluate(0, parameters=self.parameters)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\delma\\OneDrive\\Bureau\\4eme_EI\\Artificial_Inteligence\\Intership_Steve_DELMAS_2025\\venv\\Lib\\site-packages\\flwr\\server\\strategy\\fedavg.py\", line 167, in evaluate\n",
      "    eval_res = self.evaluate_fn(server_round, parameters_ndarrays, {})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\delma\\AppData\\Local\\Temp\\ipykernel_1300\\3995451472.py\", line 7, in evaluate_fn\n",
      "  File \"c:\\Users\\delma\\OneDrive\\Bureau\\4eme_EI\\Artificial_Inteligence\\Intership_Steve_DELMAS_2025\\venv\\Lib\\site-packages\\flwr\\common\\parameter.py\", line 34, in parameters_to_ndarrays\n",
      "    return [bytes_to_ndarray(tensor) for tensor in parameters.tensors]\n",
      "                                                   ^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'list' object has no attribute 'tensors'\n",
      "2025-06-25 10:36:32,537\tWARNING packaging.py:393 -- File c:\\Users\\delma\\OneDrive\\Bureau\\4eme_EI\\Artificial_Inteligence\\Intership_Steve_DELMAS_2025\\Code_final\\data\\MNIST\\raw\\train-images-idx3-ubyte is very large (44.86MiB). Consider adding this file to the 'excludes' list to skip uploading it: `ray.init(..., runtime_env={'excludes': ['c:\\Users\\delma\\OneDrive\\Bureau\\4eme_EI\\Artificial_Inteligence\\Intership_Steve_DELMAS_2025\\Code_final\\data\\MNIST\\raw\\train-images-idx3-ubyte']})`\n",
      "2025-06-25 10:36:32,753\tWARNING packaging.py:393 -- File c:\\Users\\delma\\OneDrive\\Bureau\\4eme_EI\\Artificial_Inteligence\\Intership_Steve_DELMAS_2025\\Code_final\\MNIST\\raw\\train-images-idx3-ubyte is very large (44.86MiB). Consider adding this file to the 'excludes' list to skip uploading it: `ray.init(..., runtime_env={'excludes': ['c:\\Users\\delma\\OneDrive\\Bureau\\4eme_EI\\Artificial_Inteligence\\Intership_Steve_DELMAS_2025\\Code_final\\MNIST\\raw\\train-images-idx3-ubyte']})`\n",
      "2025-06-25 10:36:32,954\tWARNING packaging.py:393 -- File c:\\Users\\delma\\OneDrive\\Bureau\\4eme_EI\\Artificial_Inteligence\\Intership_Steve_DELMAS_2025\\Code_final\\MNIST_data\\MNIST\\raw\\train-images-idx3-ubyte is very large (44.86MiB). Consider adding this file to the 'excludes' list to skip uploading it: `ray.init(..., runtime_env={'excludes': ['c:\\Users\\delma\\OneDrive\\Bureau\\4eme_EI\\Artificial_Inteligence\\Intership_Steve_DELMAS_2025\\Code_final\\MNIST_data\\MNIST\\raw\\train-images-idx3-ubyte']})`\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Exception in ServerApp thread",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m history = \u001b[43mrun_simulation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient_app\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient_app\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mserver_app\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_supernodes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_clients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\delma\\OneDrive\\Bureau\\4eme_EI\\Artificial_Inteligence\\Intership_Steve_DELMAS_2025\\venv\\Lib\\site-packages\\flwr\\simulation\\run_simulation.py:247\u001b[39m, in \u001b[36mrun_simulation\u001b[39m\u001b[34m(server_app, client_app, num_supernodes, backend_name, backend_config, enable_tf_gpu_growth, verbose_logging)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m enable_tf_gpu_growth:\n\u001b[32m    239\u001b[39m     warn_deprecated_feature_with_example(\n\u001b[32m    240\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPassing `enable_tf_gpu_growth=True` is deprecated.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    241\u001b[39m         example_message=\u001b[33m\"\u001b[39m\u001b[33mInstead, set the `TF_FORCE_GPU_ALLOW_GROWTH` environmnet \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    244\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33mflwr.simulation.run_simulationt(...)\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    245\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m247\u001b[39m \u001b[43m_run_simulation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_supernodes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_supernodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient_app\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient_app\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m    \u001b[49m\u001b[43mserver_app\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_app\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbackend_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbackend_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbackend_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbackend_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m    \u001b[49m\u001b[43menable_tf_gpu_growth\u001b[49m\u001b[43m=\u001b[49m\u001b[43menable_tf_gpu_growth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose_logging\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose_logging\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\delma\\OneDrive\\Bureau\\4eme_EI\\Artificial_Inteligence\\Intership_Steve_DELMAS_2025\\venv\\Lib\\site-packages\\flwr\\simulation\\run_simulation.py:569\u001b[39m, in \u001b[36m_run_simulation\u001b[39m\u001b[34m(num_supernodes, client_app, server_app, backend_name, backend_config, client_app_attr, server_app_attr, server_app_run_config, app_dir, flwr_dir, run, enable_tf_gpu_growth, verbose_logging, is_app)\u001b[39m\n\u001b[32m    565\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m asyncio_loop_running:\n\u001b[32m    566\u001b[39m     \u001b[38;5;66;03m# Set logger propagation to False to prevent duplicated log output in Colab.\u001b[39;00m\n\u001b[32m    567\u001b[39m     logger = set_logger_propagation(logger, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m569\u001b[39m \u001b[43m_main_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\delma\\OneDrive\\Bureau\\4eme_EI\\Artificial_Inteligence\\Intership_Steve_DELMAS_2025\\venv\\Lib\\site-packages\\flwr\\simulation\\run_simulation.py:405\u001b[39m, in \u001b[36m_main_loop\u001b[39m\u001b[34m(num_supernodes, backend_name, backend_config_stream, app_dir, is_app, enable_tf_gpu_growth, run, flwr_dir, client_app, client_app_attr, server_app, server_app_attr, server_app_run_config)\u001b[39m\n\u001b[32m    403\u001b[39m         serverapp_th.join()\n\u001b[32m    404\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m server_app_thread_has_exception.is_set():\n\u001b[32m--> \u001b[39m\u001b[32m405\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mException in ServerApp thread\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    407\u001b[39m log(DEBUG, \u001b[33m\"\u001b[39m\u001b[33mStopping Simulation Engine now.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mRuntimeError\u001b[39m: Exception in ServerApp thread"
     ]
    }
   ],
   "source": [
    "history = run_simulation(\n",
    "    client_app=client_app,\n",
    "    server_app=server,\n",
    "    num_supernodes=num_clients,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736194c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Erreur : aucune donnée trouvée dans `history.parameters`\n"
     ]
    }
   ],
   "source": [
    "final_model = Net()\n",
    "if history and hasattr(history, \"parameters\") and history.parameters:\n",
    "    final_parameters = parameters_to_ndarrays(history.parameters[-1])\n",
    "    set_weights(final_model, final_weights)\n",
    "\n",
    "    _, _, y_true, y_pred = test(final_model, testloader)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(range(10)))\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion Matrix After Federated Learning\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"⚠️ Erreur : aucune donnée trouvée dans `history.parameters`\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
